{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-Learning\n",
    "\n",
    "Definition from wiki of [Q-Learning](https://en.wikipedia.org/wiki/Q-learning). \n",
    "\n",
    ">Q-learning is a reinforcement learning technique used in machine learning. \n",
    "\n",
    ">The goal of Q-Learning is to learn a policy, which tells an agent **which action to take under which circumstances**. It does not require a model of the environment and can handle problems with stochastic transitions and rewards, without requiring adaptations.\n",
    "\n",
    ">For any finite Markov decision process (FMDP), Q-learning eventually finds an optimal policy, in the sense that the expected value of the total reward return over all successive steps, starting from the current state, is the maximum achievable. Q-learning can identify an optimal action-selection policy for any given FMDP, given infinite exploration time and an, at least partly, random policy. \"Q\" names the function that returns the reward used to provide the reinforcement and can be said to stand for the \"quality\" of an action taken in a given state.\n",
    "\n",
    "[What is Markov Decision Process?](https://en.wikipedia.org/wiki/Markov_decision_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Table\n",
    "\n",
    "Q-Table is a basic form of Q-Learning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
