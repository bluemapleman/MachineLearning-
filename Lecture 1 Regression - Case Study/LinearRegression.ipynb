{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "## Model \n",
    "\n",
    "Model is what we aim to fit/obtain in machine learning algorithm.\n",
    "\n",
    "$y=a_1x_1+a_2x_2+a_3x_3+...+a_nx_n$\n",
    "\n",
    "**fitted model**\n",
    "\n",
    "$y=a_1x_1+a_2x_2+a_3x_3+...+a_nx_n$\n",
    "\n",
    "## Loss Function \n",
    "\n",
    "Loss Function measures the difference between predicted value and true value, **only with loss function can we get a goal to optimize so that we can know how good our fitted model is**.\n",
    "\n",
    "$l(y_i,\\widehat{y_i})=\\frac{1}{2}(y_i-\\widehat{y_i})^2$\n",
    "\n",
    "So **cost function (Measures the sum of difference between predicted values and true values)** is:\n",
    "\n",
    "$L=\\frac{1}{2}\\Sigma_{i=1}^n(y_i-\\widehat{y_i})^2$\n",
    "\n",
    "## Optimization Method \n",
    "\n",
    "Optimization Method is the way how the fitted model tries to keep getting closer to the real model. More Specifically, the formula according to which the parameters of model are updated.\n",
    "\n",
    "**Gradient Decent**: \n",
    "for any parameter, we update it for each sample in follwing way:\n",
    "\n",
    "$a_i:=a_i-\\lambda\\frac{\\partial{l}}{\\partial{a_i}}=a_i-\\lambda(y_i-\\widehat{y_i})x_i$\n",
    "\n",
    "- The principle of gradient decent\n",
    "\n",
    "optimization method essentially decreases the value of cost function by updating parameters of model according to a fixed formula, which means **the formula of updating parameters can ensure that value of cost function is decreasing gradually.**\n",
    "\n",
    "The meaning of formula of gradient decent is: assign the difference between parameter value and multiple of partial derivative of loss function to parameter (gradient) and sample value to the parameter.\n",
    "\n",
    "*Refer to wiki of [Gradient Decent](https://en.wikipedia.org/wiki/Gradient_descent) to help understand math principle behind the formula.*\n",
    "\n",
    "**Attention: Model, Loss Function and Optimization Method are three key elements of a machine learning algorithm, i.e. once these three elements are decided, it refers to a certain mechine learning algorithm. Besides, we won't repeat the definition of these three concepts in later chapters.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Realization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-41389fad42b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
